{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5196756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from numba import cuda\n",
    "print(torch.cuda.is_available())\n",
    "import LocalEnergyVct as le\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f296e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(X):\n",
    "    if len(X['features'].shape) == 2:\n",
    "        X['features'] = X['features'].unsqueeze(0)\n",
    "    # print(torch.sum(X['features'][:,0:3,9],dim=1))\n",
    "    target = (X['features'][:,0:3,9]).to(device)  # /X['features'].shape[0]).squeeze().to(device)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdacd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNASeqDataset(Dataset):\n",
    "    \"\"\"RNA sequences dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, device, csv_file='data/SeqCSV/seq_frame.csv', root_dir='data/SeqCSV/', transform=None):\n",
    "        self.seq_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        # self.transform = transform\n",
    "        size = len(self.seq_frame)\n",
    "        lengths = self.seq_frame.iloc[:, 1:].astype('int64')\n",
    "        lengths = torch.from_numpy(np.array(lengths)).to(device)\n",
    "\n",
    "        # get features size\n",
    "        seq_name = os.path.join(self.root_dir, self.seq_frame.iloc[0, 0] + '.csv')\n",
    "        features = pd.read_csv(seq_name)\n",
    "        row, col = np.array(features).shape\n",
    "\n",
    "        features = torch.zeros(size,row,col)\n",
    "        for i in range(size):\n",
    "            seq_name = os.path.join(self.root_dir, self.seq_frame.iloc[i, 0] + '.csv')\n",
    "            seq = pd.read_csv(seq_name)\n",
    "            features[i,:,:] = torch.from_numpy(np.array(seq))\n",
    "        features = features.to(device)\n",
    "        self.dataset = {'lengths': lengths, 'features': features}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        lengths = self.dataset['lengths'][idx]\n",
    "        features = self.dataset['features'][idx]\n",
    "        sample = {'lengths': lengths, 'features': features}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ac9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEnergyOpt(nn.Module):\n",
    "\n",
    "    def __init__(self,fixed_pars,opt_pars):\n",
    "        super(LocalEnergyOpt, self).__init__()\n",
    "        self.opt_pars = Parameter(torch.tensor(opt_pars, dtype=torch.float, device=device, requires_grad=True))\n",
    "        self.bond_type = Parameter(torch.tensor(fixed_pars['bond_type'], dtype=torch.float, device=device, requires_grad=True))\n",
    "        self.angle_type = Parameter(torch.tensor(fixed_pars['angle_type'], dtype=torch.float, device=device, requires_grad=True))\n",
    "        self.tor_type = Parameter(torch.tensor(fixed_pars['torsion_type'], dtype=torch.float, device=device, requires_grad=True))\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        X_lengths = X['lengths']\n",
    "        X_features = X['features']\n",
    "\n",
    "        if len(X_lengths.shape) == 1:\n",
    "            X_lengths = X_lengths.unsqueeze(0)\n",
    "            X_features = X_features.unsqueeze(0)\n",
    "\n",
    "        energy = torch.zeros(X_lengths.shape[0],3).to(device)\n",
    "\n",
    "        for i in range(X_lengths.shape[0]):\n",
    "            lengths = X_lengths[i]\n",
    "            features = X_features[i]\n",
    "            if torch.is_tensor(lengths):\n",
    "                lengths = lengths.tolist()\n",
    "            atoms = features[:lengths[0],0].long()\n",
    "            # res_labels\n",
    "            # res_pointer\n",
    "            # mass\n",
    "            # charge\n",
    "            coords = features[:lengths[5],5].view(-1,3)\n",
    "            bonds = features[:lengths[6],6].long().view(-1,3)\n",
    "            angles = features[:lengths[7],7].long().view(-1,4)\n",
    "            tors = features[:lengths[8],8].long().view(-1,5)  # all indexes: not necessary to convert to tensors\n",
    "            energy[i,0] = le.bonds_energy(coords,bonds,self.bond_type,self.opt_pars)\n",
    "            energy[i,1] = le.angles_energy(atoms,coords,angles,self.angle_type,self.opt_pars)\n",
    "            energy[i,2] = le.torsions_energy(atoms,coords,tors,self.tor_type,self.opt_pars)\n",
    "\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn1(pred,target,model,lc=0.1):\n",
    "    batch_size = pred.shape[0]\n",
    "    grad_list = []\n",
    "    grad2 = 0.\n",
    "    for i,en in enumerate(pred.view(-1,)):\n",
    "        grad_list.append(torch.autograd.grad(en, model.parameters(), create_graph=True)) \n",
    "        # each element in grad_list is a tuple of tensors\n",
    "        for t in grad_list[i]:\n",
    "            grad2 += t.pow(2).sum().squeeze()\n",
    "    # print((pred - target).pow(2).sum(), lc*grad2)\n",
    "    loss = ((pred - target).pow(2).sum() + lc*grad2)/ batch_size \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn2(pred,target,model,lc=0.1):\n",
    "    batch_size = pred.shape[0]\n",
    "    grad2 = 0.\n",
    "    for en in pred.view(-1,):\n",
    "        for p in model.parameters():\n",
    "            grad2 += torch.autograd.grad(en, p, create_graph=True).pow(2).sum().squeeze()\n",
    "    loss = ((pred - target).pow(2).sum() + lc*grad2)/ batch_size \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # size = len(dataloader.dataset)\n",
    "    # num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    for X in dataloader:\n",
    "                   \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        target = get_target(X)\n",
    "        loss = loss_fn(pred, target)\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        num_batches += 1\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation   \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    print(f'Avg loss = {train_loss:>0.4f}, valid batches = {num_batches}')\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    # num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    num_batches = 0\n",
    "    test_loss = 0\n",
    "    for X in dataloader:\n",
    "        pred = model(X)\n",
    "        target = get_target(X)\n",
    "        loss = loss_fn(pred, target)\n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        num_batches += 1\n",
    "        test_loss += loss\n",
    "    test_loss /= num_batches\n",
    "    print(f'Avg test_loss = {test_loss:>0.4f}, valid batches = {num_batches}')\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = RNASeqDataset(device=device)\n",
    "print(f'dataset allocated on {device}')\n",
    "\n",
    "tot_length = len(seq_data)\n",
    "set_length = int(0.2*tot_length)\n",
    "train_set, test_set = random_split(seq_data, [tot_length - set_length, set_length], generator=torch.Generator().manual_seed(42))\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "\n",
    "batch_size = 1\n",
    "train_dataloader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=1,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=1,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LocalEnergyOpt(fixed_pars,opt_pars).to(device)\n",
    "lr = 1e-7\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience = 500, cooldown = 1000, threshold = 1e-12, verbose = True)\n",
    "loss_fn = new_loss_fn\n",
    "\n",
    "epochs = 100\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for index_epoch in range(epochs):\n",
    "    print(f'epoch {index_epoch+1}/{epochs} \\n-------------------------')\n",
    "    t0 = time.time()\n",
    "    train_tmp = new_train(train_dataloader, model2, loss_fn, optimizer)\n",
    "    test_tmp = new_test(test_dataloader, model2, loss_fn)    \n",
    "    train_loss.append(train_tmp)\n",
    "    test_loss.append(test_tmp)\n",
    "    tf = time.time()\n",
    "    print(f'time for epoch: {tf-t0} \\n')\n",
    "    \n",
    "torch.save(model2.state_dict(), 'data/Results/model2_pars.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
