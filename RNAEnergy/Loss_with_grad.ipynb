{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9f7f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from numba import cuda\n",
    "print(torch.cuda.is_available())\n",
    "import LocalEnergyVct as le\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2b4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(X):\n",
    "    if len(X['features'].shape) == 2:\n",
    "        X['features'] = X['features'].unsqueeze(0)\n",
    "    # print(torch.sum(X['features'][:,0:3,9],dim=1))\n",
    "    target = (X['features'][:,0:3,9]).to(device)  # /X['features'].shape[0]).squeeze().to(device)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb19266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNASeqDataset(Dataset):\n",
    "    \"\"\"RNA sequences dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, device, csv_file='data/SeqCSV/seq_frame.csv', root_dir='data/SeqCSV/', transform=None):\n",
    "        self.seq_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        # self.transform = transform\n",
    "        size = len(self.seq_frame)\n",
    "        lengths = self.seq_frame.iloc[:, 1:].astype('int64')\n",
    "        lengths = torch.from_numpy(np.array(lengths)).to(device)\n",
    "\n",
    "        # get features size\n",
    "        seq_name = os.path.join(self.root_dir, self.seq_frame.iloc[0, 0] + '.csv')\n",
    "        features = pd.read_csv(seq_name)\n",
    "        row, col = np.array(features).shape\n",
    "\n",
    "        features = torch.zeros(size,row,col)\n",
    "        for i in range(size):\n",
    "            seq_name = os.path.join(self.root_dir, self.seq_frame.iloc[i, 0] + '.csv')\n",
    "            seq = pd.read_csv(seq_name)\n",
    "            features[i,:,:] = torch.from_numpy(np.array(seq))\n",
    "        features = features.to(device)\n",
    "        self.dataset = {'lengths': lengths, 'features': features}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        lengths = self.dataset['lengths'][idx]\n",
    "        features = self.dataset['features'][idx]\n",
    "        sample = {'lengths': lengths, 'features': features}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d522c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEnergyOpt(nn.Module):\n",
    "\n",
    "    def __init__(self,fixed_pars,opt_pars):\n",
    "        super(LocalEnergyOpt, self).__init__()\n",
    "        self.opt_pars = Parameter(torch.tensor(opt_pars, dtype=torch.float, device=device, requires_grad=True))\n",
    "        self.bond_type = Parameter(torch.tensor(fixed_pars['bond_type'], dtype=torch.float, device=device, requires_grad=True))\n",
    "        self.angle_type = Parameter(torch.tensor(fixed_pars['angle_type'], dtype=torch.float, device=device, requires_grad=True))\n",
    "        self.tor_type = Parameter(torch.tensor(fixed_pars['torsion_type'], dtype=torch.float, device=device, requires_grad=True))\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        X_lengths = X['lengths']\n",
    "        X_features = X['features']\n",
    "\n",
    "        if len(X_lengths.shape) == 1:\n",
    "            X_lengths = X_lengths.unsqueeze(0)\n",
    "            X_features = X_features.unsqueeze(0)\n",
    "\n",
    "        energy = torch.zeros(X_lengths.shape[0],3).to(device)\n",
    "\n",
    "        for i in range(X_lengths.shape[0]):\n",
    "            lengths = X_lengths[i]\n",
    "            features = X_features[i]\n",
    "            if torch.is_tensor(lengths):\n",
    "                lengths = lengths.tolist()\n",
    "            atoms = features[:lengths[0],0].long()\n",
    "            # res_labels\n",
    "            # res_pointer\n",
    "            # mass\n",
    "            # charge\n",
    "            coords = features[:lengths[5],5].view(-1,3)\n",
    "            bonds = features[:lengths[6],6].long().view(-1,3)\n",
    "            angles = features[:lengths[7],7].long().view(-1,4)\n",
    "            tors = features[:lengths[8],8].long().view(-1,5)  # all indexes: not necessary to convert to tensors\n",
    "            energy[i,0] = le.bonds_energy(coords,bonds,self.bond_type,self.opt_pars)\n",
    "            energy[i,1] = le.angles_energy(atoms,coords,angles,self.angle_type,self.opt_pars)\n",
    "            energy[i,2] = le.torsions_energy(atoms,coords,tors,self.tor_type,self.opt_pars)\n",
    "\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c2c0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_with_grad(pred,target,model,lc=0.1):\n",
    "    batch_size = pred.shape[0]\n",
    "    grad2 = 0.\n",
    "    for en in pred.view(-1,):\n",
    "        grad_list = torch.autograd.grad(en, model.parameters(), create_graph=True)\n",
    "        for t in grad_list:\n",
    "            grad2 += t.pow(2).sum().squeeze()\n",
    "    # print((pred - target).pow(2).sum(), lc*grad2)\n",
    "    loss = ((pred - target).pow(2).sum() + lc*grad2)/ batch_size \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "213548aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_with_grad2(pred,target,model,lc=0.05):\n",
    "    batch_size = pred.shape[0]\n",
    "    grad2 = 0.\n",
    "    pred_split = torch.split(pred.view(-1,),1)\n",
    "    grad_list = torch.autograd.grad(pred_split, model.parameters(), create_graph=True)\n",
    "    for t in grad_list:\n",
    "        grad2 += t.pow(2).sum().squeeze()\n",
    "    # print((pred - target).pow(2).sum(), lc*grad2)\n",
    "    loss = ((pred - target).pow(2).sum() + lc*grad2)/ batch_size \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2171ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_parameters(model):\n",
    "    pars_list = []\n",
    "    for p in model.parameters():\n",
    "        pars_list.append(p.reshape(-1,))\n",
    "    pars_list = torch.cat(pars_list)\n",
    "    model.parameters = pars_list\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d010cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # size = len(dataloader.dataset)\n",
    "    # num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    for X in dataloader:\n",
    "                   \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        target = get_target(X)\n",
    "        # pars_list = reshape_parameters(model)\n",
    "        loss = loss_fn(pred, target, model)\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        num_batches += 1\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation   \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    print(f'Avg loss = {train_loss:>0.4f}, valid batches = {num_batches}')\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32df43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    # num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    num_batches = 0\n",
    "    test_loss = 0\n",
    "    for X in dataloader:\n",
    "        pred = model(X)\n",
    "        target = get_target(X)\n",
    "        # pars_list = reshape_parameters(model)\n",
    "        loss = loss_fn(pred, target, model)\n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        num_batches += 1\n",
    "        test_loss += loss\n",
    "    test_loss /= num_batches\n",
    "    print(f'Avg test_loss = {test_loss:>0.4f}, valid batches = {num_batches}')\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "54ed7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset allocated on cpu\n",
      "1327\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "seq_data = RNASeqDataset(device=device)\n",
    "print(f'dataset allocated on {device}')\n",
    "\n",
    "tot_length = len(seq_data)\n",
    "set_length = int(0.2*tot_length)\n",
    "train_set, test_set = random_split(seq_data, [tot_length - set_length, set_length], generator=torch.Generator().manual_seed(42))\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "\n",
    "batch_size = 1\n",
    "train_dataloader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=1,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=1,pin_memory=True)\n",
    "\n",
    "fixed_pars = pickle.load(open('data/SeqCSV/fixed_pars.p', 'rb'))\n",
    "opt_pars = pickle.load(open('data/SeqCSV/pars.p', 'rb'))\n",
    "\n",
    "model = LocalEnergyOpt(fixed_pars,opt_pars).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1bbfcbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100 \n",
      "-------------------------\n",
      "Avg loss = 18799.4356, valid batches = 1313\n",
      "Avg test_loss = 9049.5068, valid batches = 329\n",
      "time for epoch: 5.540524959564209 \n",
      "\n",
      "epoch 2/100 \n",
      "-------------------------\n",
      "Avg loss = 8572.6342, valid batches = 1313\n",
      "Avg test_loss = 7402.9292, valid batches = 329\n",
      "time for epoch: 5.205782651901245 \n",
      "\n",
      "epoch 3/100 \n",
      "-------------------------\n",
      "Avg loss = 7505.0285, valid batches = 1313\n",
      "Avg test_loss = 6858.7407, valid batches = 329\n",
      "time for epoch: 5.604363203048706 \n",
      "\n",
      "epoch 4/100 \n",
      "-------------------------\n",
      "Avg loss = 6863.6918, valid batches = 1313\n",
      "Avg test_loss = 6449.8589, valid batches = 329\n",
      "time for epoch: 5.48005747795105 \n",
      "\n",
      "epoch 5/100 \n",
      "-------------------------\n",
      "Avg loss = 6390.5934, valid batches = 1313\n",
      "Avg test_loss = 5983.9355, valid batches = 329\n",
      "time for epoch: 5.252687454223633 \n",
      "\n",
      "epoch 6/100 \n",
      "-------------------------\n",
      "Avg loss = 6047.6292, valid batches = 1313\n",
      "Avg test_loss = 5701.5430, valid batches = 329\n",
      "time for epoch: 5.051347017288208 \n",
      "\n",
      "epoch 7/100 \n",
      "-------------------------\n",
      "Avg loss = 5762.6783, valid batches = 1313\n",
      "Avg test_loss = 5480.6997, valid batches = 329\n",
      "time for epoch: 5.0634472370147705 \n",
      "\n",
      "epoch 8/100 \n",
      "-------------------------\n",
      "Avg loss = 5519.1447, valid batches = 1313\n",
      "Avg test_loss = 5322.0425, valid batches = 329\n",
      "time for epoch: 5.251823425292969 \n",
      "\n",
      "epoch 9/100 \n",
      "-------------------------\n",
      "Avg loss = 5334.3651, valid batches = 1313\n",
      "Avg test_loss = 5146.8228, valid batches = 329\n",
      "time for epoch: 5.650851726531982 \n",
      "\n",
      "epoch 10/100 \n",
      "-------------------------\n",
      "Avg loss = 5160.4990, valid batches = 1313\n",
      "Avg test_loss = 4958.0649, valid batches = 329\n",
      "time for epoch: 5.291669845581055 \n",
      "\n",
      "epoch 11/100 \n",
      "-------------------------\n",
      "Avg loss = 5021.3083, valid batches = 1313\n",
      "Avg test_loss = 4846.8452, valid batches = 329\n",
      "time for epoch: 5.042131185531616 \n",
      "\n",
      "epoch 12/100 \n",
      "-------------------------\n",
      "Avg loss = 4876.4384, valid batches = 1313\n",
      "Avg test_loss = 4814.7559, valid batches = 329\n",
      "time for epoch: 5.334274530410767 \n",
      "\n",
      "epoch 13/100 \n",
      "-------------------------\n",
      "Avg loss = 4770.0762, valid batches = 1313\n",
      "Avg test_loss = 4607.8647, valid batches = 329\n",
      "time for epoch: 5.079154014587402 \n",
      "\n",
      "epoch 14/100 \n",
      "-------------------------\n",
      "Avg loss = 4662.9447, valid batches = 1313\n",
      "Avg test_loss = 4520.0200, valid batches = 329\n",
      "time for epoch: 5.200642824172974 \n",
      "\n",
      "epoch 15/100 \n",
      "-------------------------\n",
      "Avg loss = 4563.3574, valid batches = 1313\n",
      "Avg test_loss = 4448.5171, valid batches = 329\n",
      "time for epoch: 5.320959091186523 \n",
      "\n",
      "epoch 16/100 \n",
      "-------------------------\n",
      "Avg loss = 4473.6181, valid batches = 1313\n",
      "Avg test_loss = 4353.2407, valid batches = 329\n",
      "time for epoch: 5.476910352706909 \n",
      "\n",
      "epoch 17/100 \n",
      "-------------------------\n",
      "Avg loss = 4382.9716, valid batches = 1313\n",
      "Avg test_loss = 4252.8486, valid batches = 329\n",
      "time for epoch: 5.273520231246948 \n",
      "\n",
      "epoch 18/100 \n",
      "-------------------------\n",
      "Avg loss = 4298.9843, valid batches = 1313\n",
      "Avg test_loss = 4188.5127, valid batches = 329\n",
      "time for epoch: 5.1745781898498535 \n",
      "\n",
      "epoch 19/100 \n",
      "-------------------------\n",
      "Avg loss = 4220.7700, valid batches = 1313\n",
      "Avg test_loss = 4101.6206, valid batches = 329\n",
      "time for epoch: 5.184875011444092 \n",
      "\n",
      "epoch 20/100 \n",
      "-------------------------\n",
      "Avg loss = 4144.5024, valid batches = 1313\n",
      "Avg test_loss = 4044.8401, valid batches = 329\n",
      "time for epoch: 5.241068363189697 \n",
      "\n",
      "epoch 21/100 \n",
      "-------------------------\n",
      "Avg loss = 4070.6096, valid batches = 1313\n",
      "Avg test_loss = 3977.0464, valid batches = 329\n",
      "time for epoch: 5.200246095657349 \n",
      "\n",
      "epoch 22/100 \n",
      "-------------------------\n",
      "Avg loss = 3999.8429, valid batches = 1313\n",
      "Avg test_loss = 3899.9727, valid batches = 329\n",
      "time for epoch: 5.2571001052856445 \n",
      "\n",
      "epoch 23/100 \n",
      "-------------------------\n",
      "Avg loss = 3930.8302, valid batches = 1313\n",
      "Avg test_loss = 3849.3113, valid batches = 329\n",
      "time for epoch: 5.239755153656006 \n",
      "\n",
      "epoch 24/100 \n",
      "-------------------------\n",
      "Avg loss = 3868.9204, valid batches = 1313\n",
      "Avg test_loss = 3799.0234, valid batches = 329\n",
      "time for epoch: 5.233374118804932 \n",
      "\n",
      "epoch 25/100 \n",
      "-------------------------\n",
      "Avg loss = 3804.1559, valid batches = 1313\n",
      "Avg test_loss = 3721.5623, valid batches = 329\n",
      "time for epoch: 5.274075984954834 \n",
      "\n",
      "epoch 26/100 \n",
      "-------------------------\n",
      "Avg loss = 3749.2474, valid batches = 1313\n",
      "Avg test_loss = 3663.7869, valid batches = 329\n",
      "time for epoch: 5.431906700134277 \n",
      "\n",
      "epoch 27/100 \n",
      "-------------------------\n",
      "Avg loss = 3689.6151, valid batches = 1313\n",
      "Avg test_loss = 3607.1584, valid batches = 329\n",
      "time for epoch: 5.163112163543701 \n",
      "\n",
      "epoch 28/100 \n",
      "-------------------------\n",
      "Avg loss = 3634.5661, valid batches = 1313\n",
      "Avg test_loss = 3552.5901, valid batches = 329\n",
      "time for epoch: 5.378453016281128 \n",
      "\n",
      "epoch 29/100 \n",
      "-------------------------\n",
      "Avg loss = 3578.3286, valid batches = 1313\n",
      "Avg test_loss = 3500.7383, valid batches = 329\n",
      "time for epoch: 5.326069116592407 \n",
      "\n",
      "epoch 30/100 \n",
      "-------------------------\n",
      "Avg loss = 3527.0965, valid batches = 1313\n",
      "Avg test_loss = 3454.8708, valid batches = 329\n",
      "time for epoch: 5.193907022476196 \n",
      "\n",
      "epoch 31/100 \n",
      "-------------------------\n",
      "Avg loss = 3477.8800, valid batches = 1313\n",
      "Avg test_loss = 3411.4487, valid batches = 329\n",
      "time for epoch: 5.207018613815308 \n",
      "\n",
      "epoch 32/100 \n",
      "-------------------------\n",
      "Avg loss = 3424.9604, valid batches = 1313\n",
      "Avg test_loss = 3363.6482, valid batches = 329\n",
      "time for epoch: 5.330293893814087 \n",
      "\n",
      "epoch 33/100 \n",
      "-------------------------\n",
      "Avg loss = 3382.5407, valid batches = 1313\n",
      "Avg test_loss = 3311.1748, valid batches = 329\n",
      "time for epoch: 5.360231161117554 \n",
      "\n",
      "epoch 34/100 \n",
      "-------------------------\n",
      "Avg loss = 3334.7760, valid batches = 1313\n",
      "Avg test_loss = 3278.6428, valid batches = 329\n",
      "time for epoch: 5.263664484024048 \n",
      "\n",
      "epoch 35/100 \n",
      "-------------------------\n",
      "Avg loss = 3292.9621, valid batches = 1313\n",
      "Avg test_loss = 3231.1682, valid batches = 329\n",
      "time for epoch: 5.179129362106323 \n",
      "\n",
      "epoch 36/100 \n",
      "-------------------------\n",
      "Avg loss = 3249.9027, valid batches = 1313\n",
      "Avg test_loss = 3191.1853, valid batches = 329\n",
      "time for epoch: 5.231808423995972 \n",
      "\n",
      "epoch 37/100 \n",
      "-------------------------\n",
      "Avg loss = 3207.5840, valid batches = 1313\n",
      "Avg test_loss = 3163.5308, valid batches = 329\n",
      "time for epoch: 5.455921649932861 \n",
      "\n",
      "epoch 38/100 \n",
      "-------------------------\n",
      "Avg loss = 3167.2213, valid batches = 1313\n",
      "Avg test_loss = 3112.2688, valid batches = 329\n",
      "time for epoch: 5.2272162437438965 \n",
      "\n",
      "epoch 39/100 \n",
      "-------------------------\n",
      "Avg loss = 3129.0510, valid batches = 1313\n",
      "Avg test_loss = 3079.4226, valid batches = 329\n",
      "time for epoch: 5.306910037994385 \n",
      "\n",
      "epoch 40/100 \n",
      "-------------------------\n",
      "Avg loss = 3092.3169, valid batches = 1313\n",
      "Avg test_loss = 3040.6863, valid batches = 329\n",
      "time for epoch: 5.288419008255005 \n",
      "\n",
      "epoch 41/100 \n",
      "-------------------------\n",
      "Avg loss = 3056.7341, valid batches = 1313\n",
      "Avg test_loss = 3005.7725, valid batches = 329\n",
      "time for epoch: 5.241348743438721 \n",
      "\n",
      "epoch 42/100 \n",
      "-------------------------\n",
      "Avg loss = 3022.2246, valid batches = 1313\n",
      "Avg test_loss = 2973.4695, valid batches = 329\n",
      "time for epoch: 5.296506881713867 \n",
      "\n",
      "epoch 43/100 \n",
      "-------------------------\n",
      "Avg loss = 2986.5392, valid batches = 1313\n",
      "Avg test_loss = 2944.1672, valid batches = 329\n",
      "time for epoch: 5.246693849563599 \n",
      "\n",
      "epoch 44/100 \n",
      "-------------------------\n",
      "Avg loss = 2956.3380, valid batches = 1313\n",
      "Avg test_loss = 2910.1387, valid batches = 329\n",
      "time for epoch: 5.268701791763306 \n",
      "\n",
      "epoch 45/100 \n",
      "-------------------------\n",
      "Avg loss = 2922.9643, valid batches = 1313\n",
      "Avg test_loss = 2881.8328, valid batches = 329\n",
      "time for epoch: 5.271778583526611 \n",
      "\n",
      "epoch 46/100 \n",
      "-------------------------\n",
      "Avg loss = 2893.4104, valid batches = 1313\n",
      "Avg test_loss = 2851.4199, valid batches = 329\n",
      "time for epoch: 5.190574407577515 \n",
      "\n",
      "epoch 47/100 \n",
      "-------------------------\n",
      "Avg loss = 2863.4062, valid batches = 1313\n",
      "Avg test_loss = 2825.7207, valid batches = 329\n",
      "time for epoch: 5.230210542678833 \n",
      "\n",
      "epoch 48/100 \n",
      "-------------------------\n",
      "Avg loss = 2834.7085, valid batches = 1313\n",
      "Avg test_loss = 2794.2322, valid batches = 329\n",
      "time for epoch: 5.2386884689331055 \n",
      "\n",
      "epoch 49/100 \n",
      "-------------------------\n",
      "Avg loss = 2807.7206, valid batches = 1313\n",
      "Avg test_loss = 2772.6641, valid batches = 329\n",
      "time for epoch: 5.19965124130249 \n",
      "\n",
      "epoch 50/100 \n",
      "-------------------------\n",
      "Avg loss = 2780.2866, valid batches = 1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg test_loss = 2742.8506, valid batches = 329\n",
      "time for epoch: 5.205306529998779 \n",
      "\n",
      "epoch 51/100 \n",
      "-------------------------\n",
      "Avg loss = 2753.7656, valid batches = 1313\n",
      "Avg test_loss = 2720.9739, valid batches = 329\n",
      "time for epoch: 5.505064487457275 \n",
      "\n",
      "epoch 52/100 \n",
      "-------------------------\n",
      "Avg loss = 2727.1018, valid batches = 1313\n",
      "Avg test_loss = 2695.9497, valid batches = 329\n",
      "time for epoch: 5.206534385681152 \n",
      "\n",
      "epoch 53/100 \n",
      "-------------------------\n",
      "Avg loss = 2704.6116, valid batches = 1313\n",
      "Avg test_loss = 2672.0627, valid batches = 329\n",
      "time for epoch: 5.154438018798828 \n",
      "\n",
      "epoch 54/100 \n",
      "-------------------------\n",
      "Avg loss = 2680.2198, valid batches = 1313\n",
      "Avg test_loss = 2645.6323, valid batches = 329\n",
      "time for epoch: 5.213413715362549 \n",
      "\n",
      "epoch 55/100 \n",
      "-------------------------\n",
      "Avg loss = 2655.8350, valid batches = 1313\n",
      "Avg test_loss = 2624.6897, valid batches = 329\n",
      "time for epoch: 5.293657064437866 \n",
      "\n",
      "epoch 56/100 \n",
      "-------------------------\n",
      "Avg loss = 2632.8357, valid batches = 1313\n",
      "Avg test_loss = 2603.7942, valid batches = 329\n",
      "time for epoch: 5.351626873016357 \n",
      "\n",
      "epoch 57/100 \n",
      "-------------------------\n",
      "Avg loss = 2610.1662, valid batches = 1313\n",
      "Avg test_loss = 2582.1345, valid batches = 329\n",
      "time for epoch: 5.17049765586853 \n",
      "\n",
      "epoch 58/100 \n",
      "-------------------------\n",
      "Avg loss = 2589.8074, valid batches = 1313\n",
      "Avg test_loss = 2562.3711, valid batches = 329\n",
      "time for epoch: 5.205222129821777 \n",
      "\n",
      "epoch 59/100 \n",
      "-------------------------\n",
      "Avg loss = 2567.8016, valid batches = 1313\n",
      "Avg test_loss = 2538.0029, valid batches = 329\n",
      "time for epoch: 5.334619760513306 \n",
      "\n",
      "epoch 60/100 \n",
      "-------------------------\n",
      "Avg loss = 2543.9055, valid batches = 1313\n",
      "Avg test_loss = 2526.6624, valid batches = 329\n",
      "time for epoch: 5.431498765945435 \n",
      "\n",
      "epoch 61/100 \n",
      "-------------------------\n",
      "Avg loss = 2526.2391, valid batches = 1313\n",
      "Avg test_loss = 2500.7363, valid batches = 329\n",
      "time for epoch: 5.238792419433594 \n",
      "\n",
      "epoch 62/100 \n",
      "-------------------------\n",
      "Avg loss = 2506.5791, valid batches = 1313\n",
      "Avg test_loss = 2488.3274, valid batches = 329\n",
      "time for epoch: 5.334251403808594 \n",
      "\n",
      "epoch 63/100 \n",
      "-------------------------\n",
      "Avg loss = 2487.9644, valid batches = 1313\n",
      "Avg test_loss = 2461.5049, valid batches = 329\n",
      "time for epoch: 5.293874979019165 \n",
      "\n",
      "epoch 64/100 \n",
      "-------------------------\n",
      "Avg loss = 2468.5295, valid batches = 1313\n",
      "Avg test_loss = 2446.4648, valid batches = 329\n",
      "time for epoch: 5.224969148635864 \n",
      "\n",
      "epoch 65/100 \n",
      "-------------------------\n",
      "Avg loss = 2450.4457, valid batches = 1313\n",
      "Avg test_loss = 2429.6365, valid batches = 329\n",
      "time for epoch: 5.307820796966553 \n",
      "\n",
      "epoch 66/100 \n",
      "-------------------------\n",
      "Avg loss = 2432.4407, valid batches = 1313\n",
      "Avg test_loss = 2412.7527, valid batches = 329\n",
      "time for epoch: 5.210643291473389 \n",
      "\n",
      "epoch 67/100 \n",
      "-------------------------\n",
      "Avg loss = 2416.9808, valid batches = 1313\n",
      "Avg test_loss = 2397.9517, valid batches = 329\n",
      "time for epoch: 5.1852076053619385 \n",
      "\n",
      "epoch 68/100 \n",
      "-------------------------\n",
      "Avg loss = 2401.0783, valid batches = 1313\n",
      "Avg test_loss = 2386.6414, valid batches = 329\n",
      "time for epoch: 5.216606855392456 \n",
      "\n",
      "epoch 69/100 \n",
      "-------------------------\n",
      "Avg loss = 2385.2298, valid batches = 1313\n",
      "Avg test_loss = 2365.9980, valid batches = 329\n",
      "time for epoch: 5.513216018676758 \n",
      "\n",
      "epoch 70/100 \n",
      "-------------------------\n",
      "Avg loss = 2370.8686, valid batches = 1313\n",
      "Avg test_loss = 2353.1882, valid batches = 329\n",
      "time for epoch: 5.159128189086914 \n",
      "\n",
      "epoch 71/100 \n",
      "-------------------------\n",
      "Avg loss = 2356.3012, valid batches = 1313\n",
      "Avg test_loss = 2341.6375, valid batches = 329\n",
      "time for epoch: 5.2608842849731445 \n",
      "\n",
      "epoch 72/100 \n",
      "-------------------------\n",
      "Avg loss = 2342.4815, valid batches = 1313\n",
      "Avg test_loss = 2325.9438, valid batches = 329\n",
      "time for epoch: 5.226683139801025 \n",
      "\n",
      "epoch 73/100 \n",
      "-------------------------\n",
      "Avg loss = 2329.1110, valid batches = 1313\n",
      "Avg test_loss = 2315.2632, valid batches = 329\n",
      "time for epoch: 5.320942401885986 \n",
      "\n",
      "epoch 74/100 \n",
      "-------------------------\n",
      "Avg loss = 2316.0400, valid batches = 1313\n",
      "Avg test_loss = 2298.5439, valid batches = 329\n",
      "time for epoch: 5.316222906112671 \n",
      "\n",
      "epoch 75/100 \n",
      "-------------------------\n",
      "Avg loss = 2303.1645, valid batches = 1313\n",
      "Avg test_loss = 2287.6526, valid batches = 329\n",
      "time for epoch: 5.227460861206055 \n",
      "\n",
      "epoch 76/100 \n",
      "-------------------------\n",
      "Avg loss = 2291.1467, valid batches = 1313\n",
      "Avg test_loss = 2278.9182, valid batches = 329\n",
      "time for epoch: 5.395628929138184 \n",
      "\n",
      "epoch 77/100 \n",
      "-------------------------\n",
      "Avg loss = 2279.0271, valid batches = 1313\n",
      "Avg test_loss = 2265.9968, valid batches = 329\n",
      "time for epoch: 5.2014079093933105 \n",
      "\n",
      "epoch 78/100 \n",
      "-------------------------\n",
      "Avg loss = 2267.1047, valid batches = 1313\n",
      "Avg test_loss = 2252.5415, valid batches = 329\n",
      "time for epoch: 5.376245975494385 \n",
      "\n",
      "epoch 79/100 \n",
      "-------------------------\n",
      "Avg loss = 2255.4203, valid batches = 1313\n",
      "Avg test_loss = 2247.3293, valid batches = 329\n",
      "time for epoch: 5.286175012588501 \n",
      "\n",
      "epoch 80/100 \n",
      "-------------------------\n",
      "Avg loss = 2244.4014, valid batches = 1313\n",
      "Avg test_loss = 2238.3472, valid batches = 329\n",
      "time for epoch: 5.167646884918213 \n",
      "\n",
      "epoch 81/100 \n",
      "-------------------------\n",
      "Avg loss = 2234.6368, valid batches = 1313\n",
      "Avg test_loss = 2229.6841, valid batches = 329\n",
      "time for epoch: 5.196588039398193 \n",
      "\n",
      "epoch 82/100 \n",
      "-------------------------\n",
      "Avg loss = 2224.6599, valid batches = 1313\n",
      "Avg test_loss = 2211.4807, valid batches = 329\n",
      "time for epoch: 5.259413003921509 \n",
      "\n",
      "epoch 83/100 \n",
      "-------------------------\n",
      "Avg loss = 2212.0916, valid batches = 1313\n",
      "Avg test_loss = 2205.2786, valid batches = 329\n",
      "time for epoch: 5.330892086029053 \n",
      "\n",
      "epoch 84/100 \n",
      "-------------------------\n",
      "Avg loss = 2203.3242, valid batches = 1313\n",
      "Avg test_loss = 2190.8328, valid batches = 329\n",
      "time for epoch: 5.2940826416015625 \n",
      "\n",
      "epoch 85/100 \n",
      "-------------------------\n",
      "Avg loss = 2194.3823, valid batches = 1313\n",
      "Avg test_loss = 2185.7302, valid batches = 329\n",
      "time for epoch: 5.307089567184448 \n",
      "\n",
      "epoch 86/100 \n",
      "-------------------------\n",
      "Avg loss = 2184.7713, valid batches = 1313\n",
      "Avg test_loss = 2177.6904, valid batches = 329\n",
      "time for epoch: 5.411020517349243 \n",
      "\n",
      "epoch 87/100 \n",
      "-------------------------\n",
      "Avg loss = 2175.9997, valid batches = 1313\n",
      "Avg test_loss = 2165.1292, valid batches = 329\n",
      "time for epoch: 5.294299125671387 \n",
      "\n",
      "epoch 88/100 \n",
      "-------------------------\n",
      "Avg loss = 2167.3871, valid batches = 1313\n",
      "Avg test_loss = 2158.3669, valid batches = 329\n",
      "time for epoch: 5.344301700592041 \n",
      "\n",
      "epoch 89/100 \n",
      "-------------------------\n",
      "Avg loss = 2158.8180, valid batches = 1313\n",
      "Avg test_loss = 2149.6025, valid batches = 329\n",
      "time for epoch: 5.178296089172363 \n",
      "\n",
      "epoch 90/100 \n",
      "-------------------------\n",
      "Avg loss = 2149.7067, valid batches = 1313\n",
      "Avg test_loss = 2142.7837, valid batches = 329\n",
      "time for epoch: 5.417669773101807 \n",
      "\n",
      "epoch 91/100 \n",
      "-------------------------\n",
      "Avg loss = 2141.2372, valid batches = 1313\n",
      "Avg test_loss = 2132.0708, valid batches = 329\n",
      "time for epoch: 5.257961273193359 \n",
      "\n",
      "epoch 92/100 \n",
      "-------------------------\n",
      "Avg loss = 2133.9377, valid batches = 1313\n",
      "Avg test_loss = 2125.6445, valid batches = 329\n",
      "time for epoch: 5.3235533237457275 \n",
      "\n",
      "epoch 93/100 \n",
      "-------------------------\n",
      "Avg loss = 2125.7536, valid batches = 1313\n",
      "Avg test_loss = 2121.5764, valid batches = 329\n",
      "time for epoch: 5.1605377197265625 \n",
      "\n",
      "epoch 94/100 \n",
      "-------------------------\n",
      "Avg loss = 2116.5315, valid batches = 1313\n",
      "Avg test_loss = 2115.7319, valid batches = 329\n",
      "time for epoch: 5.162408113479614 \n",
      "\n",
      "epoch 95/100 \n",
      "-------------------------\n",
      "Avg loss = 2109.9321, valid batches = 1313\n",
      "Avg test_loss = 2101.7056, valid batches = 329\n",
      "time for epoch: 5.4112725257873535 \n",
      "\n",
      "epoch 96/100 \n",
      "-------------------------\n",
      "Avg loss = 2102.3837, valid batches = 1313\n",
      "Avg test_loss = 2096.8391, valid batches = 329\n",
      "time for epoch: 5.7951743602752686 \n",
      "\n",
      "epoch 97/100 \n",
      "-------------------------\n",
      "Avg loss = 2095.1496, valid batches = 1313\n",
      "Avg test_loss = 2091.3118, valid batches = 329\n",
      "time for epoch: 5.1023640632629395 \n",
      "\n",
      "epoch 98/100 \n",
      "-------------------------\n",
      "Avg loss = 2088.3089, valid batches = 1313\n",
      "Avg test_loss = 2081.9026, valid batches = 329\n",
      "time for epoch: 5.2213616371154785 \n",
      "\n",
      "epoch 99/100 \n",
      "-------------------------\n",
      "Avg loss = 2080.6597, valid batches = 1313\n",
      "Avg test_loss = 2073.0793, valid batches = 329\n",
      "time for epoch: 5.283764839172363 \n",
      "\n",
      "epoch 100/100 \n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss = 2075.3333, valid batches = 1313\n",
      "Avg test_loss = 2071.6975, valid batches = 329\n",
      "time for epoch: 5.345065593719482 \n",
      "\n",
      "tensor([2.0742e-01, 9.6970e-01, 1.4935e+00, 2.2974e+00, 4.1144e+00, 3.1898e-01,\n",
      "        1.6127e+00, 3.6594e+00, 5.1664e-02, 2.0307e+00, 1.5223e+01, 1.0000e+00,\n",
      "        2.8000e+00, 2.5050e+00, 1.8260e+00, 3.9320e+00, 4.3090e+00, 4.7750e+00,\n",
      "        4.5460e+00, 2.8210e+00, 3.8130e+00, 3.0100e+00, 9.0800e-01, 3.0000e+00,\n",
      "        4.0000e+00, 2.2570e+00, 4.8000e-01, 5.0000e-01, 3.6814e+00, 1.0790e+01,\n",
      "        1.0912e+01, 4.9256e+00, 3.9731e-01, 6.4252e-01, 4.2243e-01, 4.8386e-01,\n",
      "        4.1908e-01, 3.3597e-01, 1.2000e+00, 1.5000e+00, 4.0000e-01, 1.8000e+00,\n",
      "        8.0000e-01, 1.4231e+02, 1.0000e+00, 0.0000e+00, 2.6810e-01])\n",
      "tensor([[ 29.9668,   3.5824],\n",
      "        [199.9992,   2.3451],\n",
      "        [199.9999,   2.6474],\n",
      "        [200.0000,   2.6466],\n",
      "        [200.0000,   3.0695],\n",
      "        [200.0000,   3.0095],\n",
      "        [200.0000,   2.4636],\n",
      "        [200.0000,   2.1910],\n",
      "        [200.0000,   1.5247],\n",
      "        [200.0000,   1.6071],\n",
      "        [200.0000,   1.4274],\n",
      "        [ 40.0000,  12.0000],\n",
      "        [ 10.0000,  12.0000],\n",
      "        [ 10.0000,  12.0000],\n",
      "        [ 10.0000,  12.0000]])\n",
      "tensor([[ 69.9999,   2.3225],\n",
      "        [ 69.9998,   2.4168],\n",
      "        [ 69.9998,   2.2119],\n",
      "        [ 69.9998,   2.3920],\n",
      "        [120.0000,   2.0421],\n",
      "        [120.0000,   1.9442],\n",
      "        [ 70.0000,   2.1125],\n",
      "        [ 69.9999,   1.9390],\n",
      "        [ 69.8874,   2.0803],\n",
      "        [ 49.8110,   1.8754],\n",
      "        [ 69.9342,   2.3303],\n",
      "        [ 99.9935,   1.7996],\n",
      "        [ 80.0000,   3.1416]])\n",
      "tensor([[ 5.5031e-01,  9.0965e-01, -3.9748e-01],\n",
      "        [ 1.2801e-01,  5.7837e-01, -2.6120e+00],\n",
      "        [ 7.2846e-01,  8.9951e-01, -3.7206e-01],\n",
      "        [ 3.1706e-01,  8.6682e-01, -2.7129e+00],\n",
      "        [ 8.0985e-01,  1.0841e+00, -2.8423e+00],\n",
      "        [ 8.0202e-01,  1.0720e+00, -2.8949e+00],\n",
      "        [ 8.1464e-01,  1.1514e+00, -2.5722e+00],\n",
      "        [ 4.7800e-02,  9.6458e-01,  2.9038e+00],\n",
      "        [ 8.5144e-01,  1.1511e+00, -2.5798e+00],\n",
      "        [ 8.2168e-01,  1.1702e+00, -2.4573e+00],\n",
      "        [ 1.2156e-01,  9.3894e-01,  2.9168e+00],\n",
      "        [ 5.8708e-02,  2.0278e-01, -2.4798e+00],\n",
      "        [ 1.6619e-01,  9.7710e-01,  2.8078e+00],\n",
      "        [ 1.1465e+00,  3.9819e-01,  1.8164e+00],\n",
      "        [ 1.1409e+00,  3.9902e-01,  1.8458e+00],\n",
      "        [ 1.3597e+00,  3.8513e-01,  1.8020e+00],\n",
      "        [ 1.3109e+00,  3.9609e-01,  1.7911e+00],\n",
      "        [ 1.1448e+00,  9.6251e-01,  3.5358e-01],\n",
      "        [ 1.1364e+00,  9.8683e-01,  2.7274e+00],\n",
      "        [ 1.0018e+00,  3.0524e+00,  1.5419e+00],\n",
      "        [ 1.0352e+00,  9.9428e-01,  2.5964e+00],\n",
      "        [ 3.3884e-01,  1.0219e+00, -5.5496e-03],\n",
      "        [ 1.5000e-01,  2.0145e+00,  3.1370e+00],\n",
      "        [ 8.4033e-01,  3.0594e+00, -2.1260e-02],\n",
      "        [ 1.0029e+00,  1.9837e+00, -5.6587e-04]])\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-7\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience = 500, cooldown = 1000, threshold = 1e-12, verbose = True)\n",
    "loss_fn = loss_with_grad2\n",
    "\n",
    "epochs = 100\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for index_epoch in range(epochs):\n",
    "    print(f'epoch {index_epoch+1}/{epochs} \\n-------------------------')\n",
    "    t0 = time.time()\n",
    "    train_tmp = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_tmp = test(test_dataloader, model, loss_fn)    \n",
    "    train_loss.append(train_tmp)\n",
    "    test_loss.append(test_tmp)\n",
    "    tf = time.time()\n",
    "    print(f'time for epoch: {tf-t0} \\n')\n",
    "    \n",
    "for p in model.parameters():\n",
    "    print(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "87262452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2747e-01,  6.5985e-01,  1.4806e+00,  2.2628e+00,  4.0585e+00,\n",
      "         8.3665e-02,  9.9526e-01,  2.8479e+00, -1.9098e-01,  2.3038e+00,\n",
      "         1.5223e+01,  1.0000e+00,  2.8000e+00,  2.5050e+00,  1.8260e+00,\n",
      "         3.9320e+00,  4.3090e+00,  4.7750e+00,  4.5460e+00,  2.8210e+00,\n",
      "         3.8130e+00,  3.0100e+00,  9.0800e-01,  3.0000e+00,  4.0000e+00,\n",
      "         2.2570e+00,  4.8000e-01,  5.0000e-01,  3.4612e+00,  1.0763e+01,\n",
      "         1.0823e+01,  4.0378e+00,  3.7675e-01,  6.0168e-01,  4.3745e-01,\n",
      "         4.9668e-01,  4.2787e-01,  3.3753e-01,  1.2000e+00,  1.5000e+00,\n",
      "         4.0000e-01,  1.8000e+00,  8.0000e-01,  1.4231e+02,  1.0000e+00,\n",
      "         0.0000e+00,  2.4391e-01])\n",
      "tensor([[ 29.9731,   3.6991],\n",
      "        [199.9973,   2.3438],\n",
      "        [199.9998,   2.6474],\n",
      "        [200.0000,   2.6459],\n",
      "        [200.0000,   3.0669],\n",
      "        [199.9999,   3.0081],\n",
      "        [199.9999,   2.4630],\n",
      "        [200.0000,   2.1899],\n",
      "        [200.0000,   1.5242],\n",
      "        [200.0000,   1.6067],\n",
      "        [200.0000,   1.4268],\n",
      "        [ 40.0000,  12.0000],\n",
      "        [ 10.0000,  12.0000],\n",
      "        [ 10.0000,  12.0000],\n",
      "        [ 10.0000,  12.0000]])\n",
      "tensor([[ 69.9996,   2.3842],\n",
      "        [ 69.9996,   2.4597],\n",
      "        [ 69.9992,   2.2510],\n",
      "        [ 69.9993,   2.4607],\n",
      "        [120.0000,   2.0398],\n",
      "        [120.0000,   1.9417],\n",
      "        [ 70.0000,   2.1123],\n",
      "        [ 69.9999,   1.9395],\n",
      "        [ 69.8699,   1.9693],\n",
      "        [ 49.7933,   1.8680],\n",
      "        [ 69.9001,   2.3280],\n",
      "        [ 99.9895,   1.7034],\n",
      "        [ 80.0000,   3.1416]])\n",
      "tensor([[ 4.0126e-01,  9.1845e-01, -4.0500e-01],\n",
      "        [ 4.3894e-02,  3.4956e-01, -2.5480e+00],\n",
      "        [ 5.8438e-01,  8.9816e-01, -3.9055e-01],\n",
      "        [ 1.3080e-01,  4.9557e-01, -2.5855e+00],\n",
      "        [ 6.3538e-01,  1.0846e+00, -2.8484e+00],\n",
      "        [ 6.2679e-01,  1.0738e+00, -2.9000e+00],\n",
      "        [ 6.3330e-01,  1.1484e+00, -2.5982e+00],\n",
      "        [ 7.0751e-02,  1.0076e+00,  3.0539e+00],\n",
      "        [ 7.1231e-01,  1.1406e+00, -2.6212e+00],\n",
      "        [ 6.5060e-01,  1.1595e+00, -2.5132e+00],\n",
      "        [ 7.0971e-02,  9.8450e-01,  3.1199e+00],\n",
      "        [ 5.2079e-02,  1.3811e-01, -2.5806e+00],\n",
      "        [ 1.0345e-01,  1.0144e+00,  3.0066e+00],\n",
      "        [ 1.3829e+00,  3.8283e-01,  1.7476e+00],\n",
      "        [ 1.2669e+00,  3.8671e-01,  1.7834e+00],\n",
      "        [ 1.4688e+00,  3.7077e-01,  1.7358e+00],\n",
      "        [ 1.4145e+00,  3.7135e-01,  1.6870e+00],\n",
      "        [ 1.1203e+00,  9.4320e-01,  3.5417e-01],\n",
      "        [ 1.0970e+00,  9.8420e-01,  2.7163e+00],\n",
      "        [ 9.6790e-01,  3.0401e+00,  1.5442e+00],\n",
      "        [ 9.8546e-01,  9.9412e-01,  2.6024e+00],\n",
      "        [ 3.2369e-01,  1.0145e+00, -5.9876e-03],\n",
      "        [ 1.2393e-01,  2.0134e+00,  3.1362e+00],\n",
      "        [ 7.9271e-01,  3.0709e+00, -2.5522e-02],\n",
      "        [ 9.6321e-01,  1.9838e+00, -3.0673e-03]])\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'data/Results/model_withgrad_pars.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62e3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
