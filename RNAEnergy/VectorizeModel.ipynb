{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import LocalEnergyVct as le\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from data_classes import RNASeqDataset\n",
    "# from my_script import get_target, loss_fn, train, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# CUDA for Pytorch\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "device ='cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_target(X):\n",
    "    if len(X['features'].shape) == 2:\n",
    "        X['features'] = X['features'].unsqueeze(0)\n",
    "    target = (X['features'][:,0:3,9])\n",
    "    return target\n",
    "\n",
    "\n",
    "# Functions without gradients in the loss\n",
    "\n",
    "def loss_fn(energy,target):\n",
    "    batch_size = energy.shape[0]\n",
    "    loss = (energy - target).pow(2).sum() / batch_size\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X in tqdm(dataloader):\n",
    "        pred = model(X)\n",
    "        target = get_target(X)\n",
    "        loss = loss_fn(pred, target)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= num_batches\n",
    "    print(f'Avg train_loss = {train_loss:>0.4f}, batches = {num_batches}')\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(dataloader):\n",
    "            pred = model(X)\n",
    "            target = get_target(X)\n",
    "            loss = loss_fn(pred, target)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= num_batches\n",
    "    print(f'Avg test_loss = {test_loss:>0.4f}, batches = {num_batches}')\n",
    "    return test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class LocalEnergyOpt(nn.Module):\n",
    "\n",
    "    def __init__(self,fixed_pars,opt_pars,device,set_to_one=True):\n",
    "        super(LocalEnergyOpt, self).__init__()\n",
    "        if set_to_one:\n",
    "            fixed_pars['bond_type'][:,0] = 1.\n",
    "            fixed_pars['angle_type'][:,0] = 1.\n",
    "            fixed_pars['torsion_type'][:,0] = 1.\n",
    "        self.device = device\n",
    "        self.opt_pars = Parameter(torch.tensor(opt_pars, dtype=torch.float, device=self.device, requires_grad=True))\n",
    "        self.bond_type = Parameter(torch.tensor(fixed_pars['bond_type'], dtype=torch.float, device=self.device, requires_grad=True))\n",
    "        self.angle_type = Parameter(torch.tensor(fixed_pars['angle_type'], dtype=torch.float, device=self.device, requires_grad=True))\n",
    "        self.tor_type = Parameter(torch.tensor(fixed_pars['torsion_type'][:,(0,2)], dtype=torch.float, device=self.device, requires_grad=True))\n",
    "        self.multiplicity = torch.tensor(fixed_pars['torsion_type'][:,1], dtype=torch.int64, device=self.device, requires_grad=False)\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        X_lengths = X['lengths']\n",
    "        X_features = X['features']\n",
    "        batch_size = X_lengths.shape[0]\n",
    "\n",
    "        energy = torch.zeros(X_lengths.shape[0],3,device=self.device)\n",
    "\n",
    "        print(X_lengths[:,5])\n",
    "        print(X_features[:,:X_lengths[:,5],5])\n",
    "        coords = X_features[:,X_lengths[:,5],5].view(batch_size,-1,3)\n",
    "\n",
    "        print(coords)\n",
    "\n",
    "        for i in range(X_lengths.shape[0]):\n",
    "            lengths = X_lengths[i]\n",
    "            features = X_features[i]\n",
    "            atoms = features[:lengths[0],0].long()\n",
    "            # res_labels\n",
    "            # res_pointer\n",
    "            # mass\n",
    "            # charge\n",
    "            coords = features[:lengths[5],5].view(-1,3)\n",
    "            bonds = features[:lengths[6],6].long().view(-1,3)\n",
    "            angles = features[:lengths[7],7].long().view(-1,4)\n",
    "            tors = features[:lengths[8],8].long().view(-1,5)\n",
    "            energy[i,0] = le.bonds_energy(coords,bonds,self.bond_type,self.opt_pars)\n",
    "            energy[i,1] = le.angles_energy(atoms,coords,angles,self.angle_type,self.opt_pars)\n",
    "            energy[i,2] = le.torsions_energy(atoms,coords,tors,self.tor_type,self.multiplicity,self.opt_pars)\n",
    "\n",
    "        return energy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 2,\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0,\n",
    "      'pin_memory': False}\n",
    "epochs = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset allocated on cpu\n",
      "Training set: 1311 elements\n",
      "Test set: 327 elements\n"
     ]
    }
   ],
   "source": [
    "# Datasets and Dataloaders\n",
    "seq_data = RNASeqDataset(device=device)\n",
    "print(f'dataset allocated on {device}')\n",
    "\n",
    "tot_length = len(seq_data)\n",
    "test_length = int(0.2*tot_length)\n",
    "train_set, test_set = random_split(seq_data, [tot_length - test_length, test_length], generator=torch.Generator().manual_seed(42))\n",
    "print(f'Training set: {len(train_set)} elements')\n",
    "print(f'Test set: {len(test_set)} elements')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "fixed_pars = pickle.load(open('data/SeqCSV/fixed_pars.p', 'rb'))\n",
    "opt_pars = pickle.load(open('data/SeqCSV/pars.p', 'rb'))\n",
    "model = LocalEnergyOpt(fixed_pars,opt_pars,device,set_to_one=False).to(device)\n",
    "torch.save(model.state_dict(), 'data/Results/initial_values.pth')\n",
    "# model.load_state_dict(torch.load(\"data/Results/model_pars.pth\"))\n",
    "# model.load_state_dict(torch.load(\"data/Results/try_batch16.npy\"))\n",
    "\n",
    "lr = 1e-7\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=500, cooldown=1000, threshold=1e-12, verbose=True)\n",
    "my_loss = loss_fn  # _with_grad\n",
    "my_train = train  # _with_grad\n",
    "my_test = test  # _with_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_dataloader = DataLoader(train_set,**params)\n",
    "test_dataloader = DataLoader(test_set,**params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([135, 135])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader):\n\u001B[0;32m----> 2\u001B[0m         pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m         target \u001B[38;5;241m=\u001B[39m get_target(X)\n\u001B[1;32m      4\u001B[0m         loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, target)\n",
      "File \u001B[0;32m~/anaconda3/envs/Gianluca/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [37]\u001B[0m, in \u001B[0;36mLocalEnergyOpt.forward\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     23\u001B[0m energy \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(X_lengths\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\u001B[38;5;241m3\u001B[39m,device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(X_lengths[:,\u001B[38;5;241m5\u001B[39m])\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mX_features\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43mX_lengths\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m     27\u001B[0m coords \u001B[38;5;241m=\u001B[39m X_features[:,X_lengths[:,\u001B[38;5;241m5\u001B[39m],\u001B[38;5;241m5\u001B[39m]\u001B[38;5;241m.\u001B[39mview(batch_size,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(coords)\n",
      "\u001B[0;31mTypeError\u001B[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "for X in tqdm(train_dataloader):\n",
    "        pred = model(X)\n",
    "        target = get_target(X)\n",
    "        loss = loss_fn(pred, target)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}